# Trinitas v3.5 - Local LLM Configuration
# Optimized for Qwen Code + GPT-OSS-120B

local_llm:
  # Model Configuration
  model:
    name: "gpt-oss-120b"
    provider: "openai-compatible"
    
  # Connection Settings
  connection:
    endpoint: "http://192.168.99.102:1234/v1"
    api_key: "${LOCAL_LLM_API_KEY}"  # Set via environment variable
    timeout: 30
    max_retries: 3
    
  # Model Optimization
  optimization:
    primary_language: "english"
    temperature: 0.7
    max_tokens: 8000
    top_p: 0.95
    frequency_penalty: 0.0
    presence_penalty: 0.0
    
  # Tool Use Configuration
  tool_capabilities:
    mcp_server: true
    parallel_tools: true
    max_parallel_tools: 5
    tool_timeout: 60
    
  # Cognitive Complexity Levels
  complexity_routing:
    mechanical:  # Level 1
      preferred_executor: "local"
      confidence: 0.95
      examples:
        - "file_search"
        - "copy_files"
        - "run_commands"
        
    analytical:  # Level 2
      preferred_executor: "local"
      confidence: 0.85
      examples:
        - "pattern_search"
        - "test_generation"
        - "documentation"
        
    reasoning:  # Level 3
      preferred_executor: "claude"
      confidence: 0.80
      examples:
        - "debug_analysis"
        - "error_investigation"
        
    creative:  # Level 4
      preferred_executor: "claude"
      confidence: 0.95
      examples:
        - "algorithm_design"
        - "api_design"
        - "architecture"
        
    strategic:  # Level 5
      preferred_executor: "claude"
      confidence: 0.99
      examples:
        - "roadmap_planning"
        - "system_design"
        
  # Task Delegation Preferences
  delegation:
    auto_delegate_threshold: 100000  # tokens
    force_delegate_threshold: 150000  # tokens
    
    prefer_local_for:
      - large_file_operations
      - test_execution
      - benchmark_running
      - documentation_generation
      - log_analysis
      - metric_collection
      
    always_claude_for:
      - security_audit
      - architecture_decision
      - api_design
      - algorithm_creation
      - strategic_planning
      
  # Sparring Partner Settings
  sparring:
    modes:
      devil_advocate:
        temperature: 0.8
        prompt_style: "challenging"
        
      alternative_finder:
        temperature: 0.9
        prompt_style: "creative"
        
      edge_case_hunter:
        temperature: 0.7
        prompt_style: "analytical"
        
      perspective_shift:
        temperature: 0.85
        prompt_style: "lateral"
        
  # Testing Configuration
  testing:
    frameworks:
      python: "pytest"
      javascript: "jest"
      typescript: "jest"
      go: "testing"
      rust: "cargo"
      
    coverage_targets:
      unit: 0.80
      integration: 0.70
      e2e: 0.60
      
    delegation_rules:
      test_generation: "local"
      test_execution: "local"
      critical_review: "claude"
      
  # Performance Settings
  performance:
    cache_enabled: true
    cache_ttl: 3600  # 1 hour
    batch_processing: true
    batch_size: 10
    
  # Monitoring
  monitoring:
    health_check_interval: 30  # seconds
    metrics_enabled: true
    log_level: "INFO"
    trace_requests: false