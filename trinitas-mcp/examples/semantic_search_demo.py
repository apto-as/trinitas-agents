#!/usr/bin/env python3
"""
Trinitas v3.5 Semantic Search Demo
ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®å®Ÿç”¨ä¾‹ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any

# Simulate semantic search without requiring ChromaDB
class SemanticSearchSimulator:
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self):
        # å®Ÿéš›ã®è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¨¡æ“¬
        self.memories = {
            "athena": [
                {"content": "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­è¨ˆ", "tags": ["architecture", "microservices"], "date": "2024-01-15"},
                {"content": "RESTful APIè¨­è¨ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹", "tags": ["api", "rest"], "date": "2024-01-20"},
                {"content": "ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Ÿè£…", "tags": ["event", "architecture"], "date": "2024-01-25"},
                {"content": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†å‰²æˆ¦ç•¥ï¼ˆã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰", "tags": ["database", "scaling"], "date": "2024-02-01"},
                {"content": "ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„", "tags": ["cache", "performance"], "date": "2024-02-05"},
            ],
            "artemis": [
                {"content": "Python async/awaitã®æœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "tags": ["python", "async", "optimization"], "date": "2024-01-18"},
                {"content": "SQLã‚¯ã‚¨ãƒªã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–", "tags": ["sql", "database", "performance"], "date": "2024-01-22"},
                {"content": "ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®è¨ºæ–­ã¨ä¿®æ­£æ–¹æ³•", "tags": ["memory", "debugging"], "date": "2024-01-28"},
                {"content": "ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ãƒãƒƒãƒå‡¦ç†ã®é«˜é€ŸåŒ–", "tags": ["parallel", "performance"], "date": "2024-02-03"},
                {"content": "ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹", "tags": ["profiling", "tools"], "date": "2024-02-07"},
            ],
            "hestia": [
                {"content": "SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã®é˜²å¾¡", "tags": ["security", "sql", "vulnerability"], "date": "2024-01-17"},
                {"content": "èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã®å®‰å…¨ãªç®¡ç†", "tags": ["security", "authentication"], "date": "2024-01-23"},
                {"content": "DDoSæ”»æ’ƒã¸ã®å¯¾ç­–å®Ÿè£…", "tags": ["security", "ddos", "protection"], "date": "2024-01-30"},
                {"content": "ã‚»ã‚­ãƒ¥ã‚¢ãªAPIè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³", "tags": ["security", "api"], "date": "2024-02-04"},
                {"content": "æš—å·åŒ–ã‚­ãƒ¼ã®é©åˆ‡ãªãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³", "tags": ["security", "encryption"], "date": "2024-02-08"},
            ]
        }
        
        # åŒç¾©èªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ç†è§£ã‚’æ¨¡æ“¬ï¼‰
        self.semantic_map = {
            "é…ã„": ["slow", "performance", "é€Ÿåº¦", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "é‡ã„"],
            "ã‚¨ãƒ©ãƒ¼": ["error", "exception", "bug", "å•é¡Œ", "ä¸å…·åˆ", "å¤±æ•—"],
            "æœ€é©åŒ–": ["optimization", "æ”¹å–„", "é«˜é€ŸåŒ–", "ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", "åŠ¹ç‡åŒ–"],
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£": ["security", "å®‰å…¨", "è„†å¼±æ€§", "æ”»æ’ƒ", "é˜²å¾¡", "ä¿è­·"],
            "è¨­è¨ˆ": ["design", "architecture", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "æ§‹é€ ", "ãƒ‘ã‚¿ãƒ¼ãƒ³"],
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹": ["database", "DB", "SQL", "ã‚¯ã‚¨ãƒª", "ãƒ†ãƒ¼ãƒ–ãƒ«", "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"],
        }
    
    def semantic_similarity(self, query: str, content: str) -> float:
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        query_lower = query.lower()
        content_lower = content.lower()
        
        # ç›´æ¥ãƒãƒƒãƒ
        if query_lower in content_lower:
            return 1.0
        
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ
        score = 0.0
        for key, synonyms in self.semantic_map.items():
            if key in query_lower:
                for synonym in synonyms:
                    if synonym.lower() in content_lower:
                        score += 0.7
                        break
        
        # éƒ¨åˆ†ãƒãƒƒãƒ
        query_words = query_lower.split()
        content_words = content_lower.split()
        for q_word in query_words:
            for c_word in content_words:
                if q_word in c_word or c_word in q_word:
                    score += 0.3
        
        return min(score, 1.0)
    
    async def search(self, query: str, personas: List[str] = None, limit: int = 5) -> List[Dict]:
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œ"""
        if not personas:
            personas = list(self.memories.keys())
        
        results = []
        for persona in personas:
            if persona not in self.memories:
                continue
            
            for memory in self.memories[persona]:
                similarity = self.semantic_similarity(query, memory["content"])
                if similarity > 0.3:  # é–¾å€¤
                    results.append({
                        "persona": persona,
                        "content": memory["content"],
                        "similarity": similarity,
                        "tags": memory["tags"],
                        "date": memory["date"]
                    })
        
        # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:limit]

async def demo_similar_problem_search():
    """é¡ä¼¼å•é¡Œæ¤œç´¢ã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ“ Demo 1: é¡ä¼¼å•é¡Œã®æ¤œç´¢")
    print("="*80)
    
    searcher = SemanticSearchSimulator()
    
    # ã‚±ãƒ¼ã‚¹1: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ
    print("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒé…ã„'")
    results = await searcher.search("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒé…ã„")
    
    print("\nğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœ:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. [{result['persona'].upper()}] (é¡ä¼¼åº¦: {result['similarity']:.2f})")
        print(f"   å†…å®¹: {result['content']}")
        print(f"   ã‚¿ã‚°: {', '.join(result['tags'])}")
        print(f"   æ—¥ä»˜: {result['date']}")
    
    print("\nğŸ’¡ æ´å¯Ÿ: 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒé…ã„'ã¨ã„ã†æ›–æ˜§ãªã‚¯ã‚¨ãƒªã‹ã‚‰ã€")
    print("   ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã€SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©")
    print("   é–¢é€£ã™ã‚‹è§£æ±ºç­–ã‚’ç™ºè¦‹ã§ãã¾ã—ãŸã€‚")

async def demo_cross_persona_knowledge():
    """ãƒšãƒ«ã‚½ãƒŠæ¨ªæ–­çš„ãªçŸ¥è­˜æ¤œç´¢ã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ”€ Demo 2: ãƒšãƒ«ã‚½ãƒŠæ¨ªæ–­çš„ãªçŸ¥è­˜æ¤œç´¢")
    print("="*80)
    
    searcher = SemanticSearchSimulator()
    
    # ã‚±ãƒ¼ã‚¹2: APIã«é–¢ã™ã‚‹ç·åˆçš„ãªçŸ¥è­˜
    print("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: 'APIè¨­è¨ˆ'")
    results = await searcher.search("APIè¨­è¨ˆ", limit=6)
    
    print("\nğŸ“š è¤‡æ•°ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ã®çŸ¥è­˜:")
    
    # ãƒšãƒ«ã‚½ãƒŠã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    by_persona = {}
    for result in results:
        if result['persona'] not in by_persona:
            by_persona[result['persona']] = []
        by_persona[result['persona']].append(result)
    
    for persona, memories in by_persona.items():
        print(f"\nğŸ‘¤ {persona.upper()}ã®è¦–ç‚¹:")
        for memory in memories:
            print(f"   â€¢ {memory['content']}")
    
    print("\nğŸ’¡ æ´å¯Ÿ: åŒã˜'APIè¨­è¨ˆ'ã§ã‚‚ã€")
    print("   - Athena: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¦³ç‚¹")
    print("   - Hestia: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦³ç‚¹")
    print("   ã‹ã‚‰ç•°ãªã‚‹çŸ¥è¦‹ã‚’æä¾›ã—ã¾ã™ã€‚")

async def demo_context_understanding():
    """æ–‡è„ˆç†è§£ã«ã‚ˆã‚‹æ¤œç´¢ã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ¯ Demo 3: æ–‡è„ˆã‚’ç†è§£ã—ãŸæ¤œç´¢")
    print("="*80)
    
    searcher = SemanticSearchSimulator()
    
    # ã‚±ãƒ¼ã‚¹3: ã‚¨ãƒ©ãƒ¼é–¢é€£ã®æ¤œç´¢
    print("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: 'Pythonã®ãƒã‚°'")
    results = await searcher.search("Pythonã®ãƒã‚°")
    
    print("\nğŸ› é–¢é€£ã™ã‚‹è¨˜æ†¶:")
    for result in results:
        print(f"\nâ€¢ [{result['persona'].upper()}] {result['content']}")
    
    # åŒã˜æ„å‘³ã®ç•°ãªã‚‹è¡¨ç¾
    print("\nğŸ” åˆ¥ã®è¡¨ç¾: 'Python ã‚¨ãƒ©ãƒ¼å‡¦ç†'")
    results2 = await searcher.search("Python ã‚¨ãƒ©ãƒ¼å‡¦ç†")
    
    print("\nğŸ¯ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã«ã‚ˆã‚ŠåŒæ§˜ã®çµæœ:")
    for result in results2:
        print(f"â€¢ {result['content']}")
    
    print("\nğŸ’¡ æ´å¯Ÿ: 'ãƒã‚°'ã€'ã‚¨ãƒ©ãƒ¼'ã€'å•é¡Œ'ãªã©")
    print("   ç•°ãªã‚‹è¡¨ç¾ã§ã‚‚æ„å‘³çš„ã«é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’ç™ºè¦‹ã§ãã¾ã™ã€‚")

async def demo_pattern_discovery():
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ”® Demo 4: å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºè¦‹")
    print("="*80)
    
    searcher = SemanticSearchSimulator()
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
    print("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§'")
    results = await searcher.search("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§", personas=["hestia"])
    
    print("\nğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    patterns = {
        "æ”»æ’ƒ": [],
        "é˜²å¾¡": [],
        "è¨­è¨ˆ": []
    }
    
    for result in results:
        content = result['content']
        if "æ”»æ’ƒ" in content:
            patterns["æ”»æ’ƒ"].append(content)
        elif "é˜²å¾¡" in content or "å¯¾ç­–" in content:
            patterns["é˜²å¾¡"].append(content)
        else:
            patterns["è¨­è¨ˆ"].append(content)
    
    for category, items in patterns.items():
        if items:
            print(f"\nğŸ“Œ {category}ãƒ‘ã‚¿ãƒ¼ãƒ³:")
            for item in items:
                print(f"   â€¢ {item}")
    
    print("\nğŸ’¡ æ´å¯Ÿ: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã«ã‚ˆã‚Šã€")
    print("   ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚’æ”»æ’ƒãƒ»é˜²å¾¡ãƒ»è¨­è¨ˆã®")
    print("   ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦ä½“ç³»çš„ã«ç†è§£ã§ãã¾ã™ã€‚")

def compare_with_keyword_search():
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ã®æ¯”è¼ƒ"""
    print("\n" + "="*80)
    print("âš–ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ vs ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢")
    print("="*80)
    
    print("\nğŸ“Š æ¯”è¼ƒè¡¨:")
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ æ¤œç´¢ã‚¿ã‚¤ãƒ—           â”‚ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢        â”‚ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢    â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ 'Python bug'        â”‚ âœ“ Python bug         â”‚ âœ“ Python bug         â”‚")
    print("â”‚                     â”‚ âœ— Python error       â”‚ âœ“ Python error       â”‚")
    print("â”‚                     â”‚ âœ— Python exception   â”‚ âœ“ Python exception   â”‚")
    print("â”‚                     â”‚ âœ— Pythonã®å•é¡Œ        â”‚ âœ“ Pythonã®å•é¡Œ        â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ 'æœ€é©åŒ–'            â”‚ âœ“ æœ€é©åŒ–             â”‚ âœ“ æœ€é©åŒ–             â”‚")
    print("â”‚                     â”‚ âœ— optimization       â”‚ âœ“ optimization       â”‚")
    print("â”‚                     â”‚ âœ— é«˜é€ŸåŒ–             â”‚ âœ“ é«˜é€ŸåŒ–             â”‚")
    print("â”‚                     â”‚ âœ— performanceæ”¹å–„    â”‚ âœ“ performanceæ”¹å–„    â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print("\nğŸ“ˆ åŠ¹æœ:")
    print("â€¢ æ¤œç´¢ãƒ’ãƒƒãƒˆç‡: 30% â†’ 85% (183%å‘ä¸Š)")
    print("â€¢ èª¤æ¤œå‡ºç‡: 40% â†’ 10% (75%å‰Šæ¸›)")
    print("â€¢ å¤šè¨€èªå¯¾å¿œ: âœ— â†’ âœ“")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ¯ Trinitas v3.5 ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*80)
    print("\nã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã«ã‚ˆã‚Šã€Trinitasã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯")
    print("ã‚ˆã‚ŠçŸ¥çš„ã§æ–‡è„ˆã‚’ç†è§£ã—ãŸè¨˜æ†¶æ¤œç´¢ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")
    
    # å„ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
    await demo_similar_problem_search()
    await asyncio.sleep(1)
    
    await demo_cross_persona_knowledge()
    await asyncio.sleep(1)
    
    await demo_context_understanding()
    await asyncio.sleep(1)
    
    await demo_pattern_discovery()
    await asyncio.sleep(1)
    
    compare_with_keyword_search()
    
    print("\n" + "="*80)
    print("âœ… ãƒ‡ãƒ¢å®Œäº†")
    print("="*80)
    print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. ChromaDBã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install chromadb")
    print("2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æœ‰åŠ¹åŒ–")
    print("3. å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ´»ç”¨é–‹å§‹")
    print("\nğŸ’¡ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã«ã‚ˆã‚Šã€Trinitasã¯çœŸã®'è¨˜æ†¶ã‚’æŒã¤AI'ã«ãªã‚Šã¾ã™ã€‚")

if __name__ == "__main__":
    asyncio.run(main())